{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "\n",
    "#location to current directory\n",
    "file_path = os.path.dirname(arcpy.mp.ArcGISProject('CURRENT').filePath)\n",
    "os.chdir(file_path)\n",
    "#absolute Path for geodatabase\n",
    "arcpy.env.workspace = file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the location we want to travel to/from given the events.\n",
    "\n",
    "#Coordinate intersection of Oak St and Washington Ave (longitude, latitude)\n",
    "facility_coords = (-93.2265955, 44.9754918)\n",
    "\n",
    "# Name of the new shapefile\n",
    "shapefile_name = \"Stadium_Village.shp\"\n",
    "\n",
    "# Spatial reference (can be an EPSG code, a full path to a PRJ file, or an arcpy.SpatialReference object)\n",
    "# Example: WGS 1984\n",
    "spatial_ref = arcpy.SpatialReference(4326)\n",
    "\n",
    "# Create the point shapefile\n",
    "dest_point = arcpy.CreateFeatureclass_management(arcpy.env.workspace, shapefile_name, \"POINT\", spatial_reference=spatial_ref)\n",
    "\n",
    "# Create a new insert cursor for adding features to the shapefile\n",
    "with arcpy.da.InsertCursor(shapefile_name, [\"SHAPE@XY\"]) as cursor:\n",
    "    # Add the facility point\n",
    "    cursor.insertRow([facility_coords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 27, 2024 3:13:20 PM\",\"WARNING 030326: The search_criteria parameter is not supported on the portal used as the network data source for this layer and will be ignored.\",\"1 features located out of 1.\",\"Succeeded at Tuesday, February 27, 2024 3:13:21 PM (Elapsed Time: 1.15 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'No Traffic Baseline'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make 2 Service Area Analysis Layers\n",
    "\n",
    "#Analysis layer 1: No Traffic Baseline (Wednesday, July 12, 2023 at 3:00am)\n",
    "##Output: Traffic analysis layer lines\n",
    "no_traffic_layer = arcpy.na.MakeServiceAreaAnalysisLayer(\n",
    "    network_data_source=\"https://www.arcgis.com/\",\n",
    "    layer_name=\"No Traffic Baseline\",\n",
    "    travel_mode=\"Driving Time\",\n",
    "    travel_direction=\"TO_FACILITIES\",\n",
    "    cutoffs=[10],\n",
    "    time_of_day=\"7/12/2023 3:00:00 AM\",\n",
    "    time_zone=\"LOCAL_TIME_AT_LOCATIONS\",\n",
    "    output_type=\"LINES\",\n",
    "    polygon_detail=\"STANDARD\",\n",
    "    geometry_at_overlaps=\"OVERLAP\",\n",
    "    geometry_at_cutoffs=\"RINGS\",\n",
    "    polygon_trim_distance=\"100 Meters\",\n",
    "    exclude_sources_from_polygon_generation=None,\n",
    "    accumulate_attributes=None,\n",
    "    ignore_invalid_locations=\"SKIP\"\n",
    ")\n",
    "\n",
    "\n",
    "#Adding destination location to the layer\n",
    "arcpy.na.AddLocations(\n",
    "    in_network_analysis_layer=no_traffic_layer,\n",
    "    sub_layer=\"Facilities\",\n",
    "    in_table=dest_point,\n",
    "    field_mappings=\"Name # #;CurbApproach # 0;Attr_Minutes # 0;Attr_TravelTime # 0;Attr_Miles # 0;Attr_Kilometers # 0;Attr_TimeAt1KPH # 0;Attr_WalkTime # 0;Attr_TruckMinutes # 0;Attr_TruckTravelTime # 0;Breaks_Minutes # #;Breaks_TravelTime # #;Breaks_Miles # #;Breaks_Kilometers # #;Breaks_TimeAt1KPH # #;Breaks_WalkTime # #;Breaks_TruckMinutes # #;Breaks_TruckTravelTime # #\",\n",
    "    search_tolerance=\"20000 Meters\",\n",
    "    sort_field=None,\n",
    "    search_criteria=\"main.Routing_Streets SHAPE\",\n",
    "    match_type=\"MATCH_TO_CLOSEST\",\n",
    "    append=\"APPEND\",\n",
    "    snap_to_position_along_network=\"NO_SNAP\",\n",
    "    snap_offset=\"5 Meters\",\n",
    "    exclude_restricted_elements=\"EXCLUDE\",\n",
    "    search_query=None,\n",
    "    allow_auto_relocate=\"ALLOW\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 27, 2024 3:13:25 PM\",\"WARNING 030326: The search_criteria parameter is not supported on the portal used as the network data source for this layer and will be ignored.\",\"1 features located out of 1.\",\"Succeeded at Tuesday, February 27, 2024 3:13:26 PM (Elapsed Time: 0.55 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'Large Event'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis layer 2: Traffic event (Ex. October 27, 2023 7:45pm; Gopher Hockey VS Badgers)\n",
    "event_time = \"10/27/2023 7:45:00 PM\"\n",
    "name_event = \"Large Event\"\n",
    "\n",
    "traffic_layer = arcpy.na.MakeServiceAreaAnalysisLayer(\n",
    "    network_data_source=\"https://www.arcgis.com/\",\n",
    "    layer_name=name_event,\n",
    "    travel_mode=\"Driving Time\",\n",
    "    travel_direction=\"TO_FACILITIES\",\n",
    "    cutoffs=[10],\n",
    "    time_of_day=event_time,\n",
    "    time_zone=\"LOCAL_TIME_AT_LOCATIONS\",\n",
    "    output_type=\"LINES\",\n",
    "    polygon_detail=\"STANDARD\",\n",
    "    geometry_at_overlaps=\"OVERLAP\",\n",
    "    geometry_at_cutoffs=\"RINGS\",\n",
    "    polygon_trim_distance=\"100 Meters\",\n",
    "    exclude_sources_from_polygon_generation=None,\n",
    "    accumulate_attributes=None,\n",
    "    ignore_invalid_locations=\"SKIP\"\n",
    ")\n",
    "\n",
    "\n",
    "#Adding destination location to the layer\n",
    "arcpy.na.AddLocations(\n",
    "    in_network_analysis_layer=traffic_layer,\n",
    "    sub_layer=\"Facilities\",\n",
    "    in_table=dest_point,\n",
    "    field_mappings=\"Name # #;CurbApproach # 0;Attr_Minutes # 0;Attr_TravelTime # 0;Attr_Miles # 0;Attr_Kilometers # 0;Attr_TimeAt1KPH # 0;Attr_WalkTime # 0;Attr_TruckMinutes # 0;Attr_TruckTravelTime # 0;Breaks_Minutes # #;Breaks_TravelTime # #;Breaks_Miles # #;Breaks_Kilometers # #;Breaks_TimeAt1KPH # #;Breaks_WalkTime # #;Breaks_TruckMinutes # #;Breaks_TruckTravelTime # #\",\n",
    "    search_tolerance=\"20000 Meters\",\n",
    "    sort_field=None,\n",
    "    search_criteria=\"main.Routing_Streets SHAPE\",\n",
    "    match_type=\"MATCH_TO_CLOSEST\",\n",
    "    append=\"APPEND\",\n",
    "    snap_to_position_along_network=\"NO_SNAP\",\n",
    "    snap_offset=\"5 Meters\",\n",
    "    exclude_restricted_elements=\"EXCLUDE\",\n",
    "    search_query=None,\n",
    "    allow_auto_relocate=\"ALLOW\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solve the network dataset\n",
    "##THIS COSTS ESRI CREDITS\n",
    "solved_no_traffic = arcpy.na.Solve(no_traffic_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solve the network dataset\n",
    "##THIS COSTS ESRI CREDITS\n",
    "solved_traffic = arcpy.na.Solve(traffic_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 27, 2024 3:13:49 PM\",\"Succeeded at Tuesday, February 27, 2024 3:13:52 PM (Elapsed Time: 2.69 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Logan\\\\Documents\\\\ArcGIS\\\\Projects\\\\MyProject1\\\\no_traffic_lines.shp'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the Service Area Polygons sublayer\n",
    "no_traffic_sublayer = no_traffic_layer.getOutput(0)\n",
    "no_traffic_sublayer = arcpy.na.GetNASublayer(no_traffic_sublayer, \"SALines\")\n",
    "\n",
    "# Export the service area polygons to a new shapefile\n",
    "output_shapefile = \"no_traffic_lines.shp\"\n",
    "arcpy.management.CopyFeatures(no_traffic_sublayer, output_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 27, 2024 3:13:52 PM\",\"Succeeded at Tuesday, February 27, 2024 3:13:55 PM (Elapsed Time: 2.81 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Logan\\\\Documents\\\\ArcGIS\\\\Projects\\\\MyProject1\\\\traffic_lines.shp'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the Service Area Polygons sublayer\n",
    "traffic_sublayer = no_traffic_layer.getOutput(0)\n",
    "traffic_sublayer = arcpy.na.GetNASublayer(traffic_sublayer, \"SALines\")\n",
    "\n",
    "# Export the service area polygons to a new shapefile\n",
    "output_shapefile = \"traffic_lines.shp\"\n",
    "arcpy.management.CopyFeatures(traffic_sublayer, output_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline extent is larger than traffic extent. Data is good.\n"
     ]
    }
   ],
   "source": [
    "#ROAD NETWORK QAQC\n",
    "\n",
    "baseline_dataset = no_traffic_sublayer\n",
    "event_dataset = traffic_sublayer\n",
    "\n",
    "\n",
    "#Completeness/Logical Consistency.\n",
    "#Check if the baseline (no traffic) engulfs the event (traffic-filled) data. This ensures all the data can be compared between the two sets.\n",
    "\n",
    "# Get the minimum bounding geometries (extent) of each dataset\n",
    "baseline_extent = arcpy.Describe(baseline_dataset).extent\n",
    "event_extent = arcpy.Describe(event_dataset).extent\n",
    "\n",
    "# Check if baseline encompasses event data\n",
    "encompasses = (baseline_extent.contains(event_extent))\n",
    "\n",
    "if encompasses:\n",
    "    print(\"Baseline extent is larger than traffic extent. Data is good.\")\n",
    "else:\n",
    "    print(\"Baseline extent is smaller than traffic extent. Data is not good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do both datasets have the same columns? True\n"
     ]
    }
   ],
   "source": [
    "# Get the list of fields for each dataset\n",
    "\n",
    "# Use Describe to get dataset information\n",
    "base_desc = arcpy.Describe(baseline_dataset)\n",
    "event_desc = arcpy.Describe(event_dataset)\n",
    "\n",
    "# List all field names from the dataset\n",
    "base_field_names = [field.name for field in base_desc.fields]\n",
    "event_field_names = [field.name for field in event_desc.fields]\n",
    "\n",
    "# Compare the fields\n",
    "same_columns = set(base_field_names) == set(event_field_names)\n",
    "\n",
    "print(f\"Do both datasets have the same columns? {same_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Dataset Isolated Segments: []\n",
      "Event Dataset Isolated Segments: []\n"
     ]
    }
   ],
   "source": [
    "def check_for_isolated_segments(input_dataset):\n",
    "\n",
    "    # Define the output dataset for the spatial join\n",
    "    output_dataset = \"temp_data.shp\"\n",
    "\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "    target_features=input_dataset,\n",
    "    join_features=input_dataset,\n",
    "    out_feature_class=output_dataset,\n",
    "    join_operation=\"JOIN_ONE_TO_MANY\",\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    match_option=\"INTERSECT\",\n",
    "    search_radius=None,\n",
    "    distance_field_name=\"\",\n",
    "    match_fields=None\n",
    "    )\n",
    "    \n",
    "    # Summarize the join count by the original feature's unique ID\n",
    "    summary_table = arcpy.CreateUniqueName(\"JoinCountSummary.csv\", arcpy.env.workspace)\n",
    "    \n",
    "    arcpy.analysis.Statistics(\n",
    "    in_table=output_dataset,\n",
    "    out_table=summary_table,\n",
    "    statistics_fields=\"Join_Count SUM\",\n",
    "    case_field=\"TARGET_FID\",\n",
    "    concatenation_separator=\"\"\n",
    "    )\n",
    "    #arcpy.Statistics_analysis(output_dataset, summary_table, [[\"Join_Count\", \"SUM\"]], \"TARGET_FID\")\n",
    "    \n",
    "    # Find features that have a SUM_JoinCount == 1, indicating no joins to other features\n",
    "    isolated_segments = [row[0] for row in arcpy.da.SearchCursor(summary_table, [\"TARGET_FID\"], \"SUM_Join_Count = 1\")]\n",
    "    \n",
    "    # Clean up temporary datasets\n",
    "    arcpy.Delete_management(output_dataset)\n",
    "    arcpy.Delete_management(summary_table)\n",
    "    \n",
    "    # Return list of isolated segment IDs\n",
    "    return isolated_segments\n",
    "\n",
    "# Check for isolated segments in both datasets\n",
    "baseline_isolated_segments = check_for_isolated_segments(baseline_dataset)\n",
    "event_isolated_segments = check_for_isolated_segments(event_dataset)\n",
    "\n",
    "print(\"Baseline Dataset Isolated Segments:\", baseline_isolated_segments)\n",
    "print(\"Event Dataset Isolated Segments:\", event_isolated_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Traffic Baseline: No missing values found.\n",
      "Large Event: No missing values found.\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(dataset, fields):\n",
    "    missing_values = {}\n",
    "    for field in fields:\n",
    "        with arcpy.da.SearchCursor(dataset, [field]) as cursor:\n",
    "            for row in cursor:\n",
    "                if row[0] is None:\n",
    "                    if field not in missing_values:\n",
    "                        missing_values[field] = 1\n",
    "                    else:\n",
    "                        missing_values[field] += 1\n",
    "                        \n",
    "    if not missing_values:\n",
    "        return \"No missing values found.\"\n",
    "    else:\n",
    "        return f\"Missing values: {missing_values}\"\n",
    "\n",
    "fields_to_check = [\"FromCumul_TravelTime\", \"FromCumul_Kilometers\", \"ToCumul_TravelTime\", \"ToCumul_Kilometers\"]\n",
    "\n",
    "# Check for both datasets\n",
    "print(\"No Traffic Baseline:\", check_missing_values(baseline_dataset, fields_to_check))\n",
    "print(\"Large Event:\", check_missing_values(event_dataset, fields_to_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
